## 基础环境搭建

准备三台服务器,此处使用aliyun ECS 2核4G 三台

修改hostname，此处改为hadoop01,hadoop02,hadoop03,修改之后需要重新启动生效

```java
vi /etc/hostname
```

修改etc文件

```java
vi /etc/hosts
//将下边内容加入文件中
172.20.175.6 hadoop01
172.20.175.7 hadoop02
172.20.175.8 hadoop03
// 分别ping一下其他三台，验证是否生效
ping hadoop01
ping hadoop02
ping hadoop03
```

下载Hadoop和JDK

```java
wget https://dlcdn.apache.org/hadoop/common/hadoop-2.10.2/hadoop-2.10.2.tar.gz --no-check-certificate
jdk官网自行下载
```

解压

```java
tar -zxvf jdk-8u271-linux-x64.tar.gz
tar -zxvf hadoop-2.10.2.tar.gz
```

增加jdk和Hadoop环境变量

```java
vi /etc/profile

追加如下内容：
HADOOP_HOME=/opt/hadoop-2.10.2
JAVA_HOME=/opt/jdk1.8.0_271
JRE_HOME=/opt/jdk1.8.0_271/jre
PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$PATH
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
export JAVA_HOME JRE_HOME PATH CLASSPATH

//使修改立即生效
source /etc/profile   
echo $JAVA_HOME
javac -version
```

配置免密登录,并将自己的授权文件分发给其他两台

```java
ssh-keygen -t rsa   //连续按三次回车
ssh-copy-id -i ~/.ssh/id_rsa.pub root@服务器IP //复制到其他服务器

cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys //将自己的授权文件给自己
chmod 0600 ~/.ssh/authorized_keys
```

### Hadoop配置

- 修改`/opt/module/hadoop-2.7.2/etc/hadoop`文件夹中的配置文件

  ```java
  <configuration>
  	<property>
  		<name>fs.defaultFS</name>
          <value>hdfs://hadoop01:9000</value>
  	</property>
  	<!-- 指定hadoop运行时产生文件的存储目录 -->
  	<property>
  		<name>hadoop.tmp.dir</name>
  		<value>/opt/module/hadoop-2.7.2/data/tmp</value>
  	</property>
  </configuration>
  ```

  hdfs-site.xml

  ```java
  <configuration>
          <property>
                  <name>dfs.replication</name>
                  <value>3</value>
          </property>
          <property>
          <name>dfs.namenode.secondary.http-address</name>
          <value>hadoop03:50090</value>
      </property>
  </configuration>
  ```

  slaves

  ```java
  #删掉了localhost，加入以下内容
  hadoop01
  hadoop02
  hadoop03
  ```

  yarn-site.xml

  ```java
  <!-- reducer获取数据的方式 -->
      <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
      </property>
  
  <!-- 指定YARN的ResourceManager的地址 -->
      <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>hadoop01</value>
      </property>
  ```

  mapred-site.xml

  ```java
  <configuration>
  <!-- 指定mr运行在yarn上 -->
  	<property>
  		<name>mapreduce.framework.name</name>
  		<value>yarn</value>
  	</property>
  </configuration>
  ```

- 可能找不到 JAVA_HOME

​	   修改hadoop-env.sh (我的hadoop安装在/opt/hadoop-2.10.2/etc/hadoop/hadoop-env.sh 目录下)

```java
#export JAVA_HOME=${JAVA_HOME} //原来

export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_121 //修改后
```

分发到其他两台

  ```java
  scp -r /opt/module/hadoop-2.7.2/etc/hadoop hadoop02:/opt/module/hadoop-2.7.2/etc/
  scp -r /opt/module/hadoop-2.7.2/etc/hadoop hadoop03:/opt/module/hadoop-2.7.2/etc/
  ```

## 集群启动

首次启动集群，需要格式化namenode

```java
hdfs namenode -format
```

在Hadoop01中启动HDFS

```java
sbin/start-dfs.sh
```
在在Hadoop01中启动yarn
```java
sbin/start-yarn.sh
```

jps查看进程

```java
[root@hadoop01 hadoop-2.10.2]# jps
8305 NameNode //hdfs
8819 NodeManager
8713 ResourceManager
9163 Jps
8447 DataNode
[root@hadoop02 scala-2.13.8]# jps
3395 DataNode
3512 NodeManager
3660 Jps
[root@hadoop03 scala-2.13.8]# jps
4339 Jps
4186 NodeManager
3996 DataNode
4108 SecondaryNameNode
```

在阿里云ECS控制台中将Hadoop01服务器的`安全组规则`中开放50070端口h和8088

- 在HDFS启动的时候，访问`http://hadoop01's公网IP:50070`
- 在yarn启动的时候，访问`http://hadoop01's公网IP:8088

其他命令：

```java
sbin/start-dfs.sh
sbin/stop-dfs.sh

sbin/start-yarn.sh
sbin/stop-yarn.sh

start-all.sh
stop-all.sh
```



## 踩坑记录：

1. 找不到JAVA_HOME

修改hadoop-env.sh (我的hadoop安装在/usr/local/ 目录下)

```java
#export JAVA_HOME=${JAVA_HOME} //原来

export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_121 //修改后
```

2. 多次format导致dataNode启动失败

```java
rm -rf /tmp/hadoop-root/*
hdfs namenode -format
```



参考：https://blog.csdn.net/u013247765/article/details/68487214

https://daisine.github.io/hadoops/
